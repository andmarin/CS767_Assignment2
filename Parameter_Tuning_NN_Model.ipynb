{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook is to test different parameter values for the neural net model for the MNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the MNIST data\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "x_train, y_train = x_train[:6000], y_train[:6000]\n",
    "\n",
    "# Dictionary to store parameter values and results\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create, compile, train, and evaluate the model\n",
    "def train_and_evaluate(layer_size, dropout_rate, learning_rate):\n",
    "    model = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "        tf.keras.layers.Dense(layer_size, activation='relu'),\n",
    "        tf.keras.layers.Dropout(dropout_rate),\n",
    "        tf.keras.layers.Dense(10)\n",
    "    ])\n",
    "\n",
    "    # Compile with custom learning rate\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, epochs=5, verbose=0)\n",
    "    \n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=0)\n",
    "    \n",
    "    return test_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameter values to test\n",
    "layer_sizes = [64, 128, 256, 512, 1024]  # Example: half, original, and double the initial size\n",
    "dropout_rates = [0.1, 0.2, 0.3]  # Example: lower, original, higher\n",
    "learning_rates = [0.001, 0.005, 0.01]  # Example: original, lower, higher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marinand\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Loop through all combinations of parameters\n",
    "for layer_size in layer_sizes:\n",
    "    for dropout_rate in dropout_rates:\n",
    "        for learning_rate in learning_rates:\n",
    "            accuracy = train_and_evaluate(layer_size, dropout_rate, learning_rate)\n",
    "            # Store the results in the dictionary\n",
    "            results.append({\n",
    "                'Layer Size': layer_size,\n",
    "                'Dropout Rate': dropout_rate,\n",
    "                'Learning Rate': learning_rate,\n",
    "                'Test Accuracy': accuracy\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Layer Size  Dropout Rate  Learning Rate  Test Accuracy\n",
      "0         1024           0.2          0.001         0.9503\n",
      "1          256           0.1          0.005         0.9486\n",
      "2          256           0.3          0.005         0.9451\n",
      "3         1024           0.3          0.001         0.9447\n",
      "4          512           0.1          0.001         0.9446\n",
      "5          512           0.2          0.001         0.9433\n",
      "6         1024           0.1          0.001         0.9425\n",
      "7          256           0.2          0.005         0.9424\n",
      "8          512           0.3          0.005         0.9422\n",
      "9          512           0.3          0.001         0.9418\n",
      "10         512           0.1          0.010         0.9399\n",
      "11         128           0.3          0.005         0.9399\n",
      "12        1024           0.2          0.005         0.9385\n",
      "13         256           0.2          0.001         0.9372\n",
      "14         256           0.3          0.001         0.9358\n",
      "15         128           0.2          0.001         0.9353\n",
      "16         128           0.1          0.005         0.9350\n",
      "17         512           0.2          0.010         0.9346\n",
      "18        1024           0.3          0.005         0.9340\n",
      "19         512           0.2          0.005         0.9336\n",
      "20         128           0.2          0.005         0.9333\n",
      "21         128           0.1          0.001         0.9332\n",
      "22         256           0.1          0.001         0.9331\n",
      "23          64           0.3          0.005         0.9325\n",
      "24         128           0.1          0.010         0.9323\n",
      "25         256           0.1          0.010         0.9321\n",
      "26        1024           0.1          0.010         0.9314\n",
      "27          64           0.2          0.005         0.9311\n",
      "28         512           0.1          0.005         0.9304\n",
      "29         128           0.3          0.001         0.9291\n",
      "30         256           0.3          0.010         0.9291\n",
      "31         512           0.3          0.010         0.9284\n",
      "32          64           0.1          0.005         0.9271\n",
      "33         128           0.3          0.010         0.9259\n",
      "34          64           0.3          0.010         0.9255\n",
      "35          64           0.2          0.001         0.9254\n",
      "36        1024           0.1          0.005         0.9253\n",
      "37          64           0.1          0.010         0.9250\n",
      "38         256           0.2          0.010         0.9229\n",
      "39          64           0.1          0.001         0.9218\n",
      "40         128           0.2          0.010         0.9218\n",
      "41        1024           0.3          0.010         0.9216\n",
      "42          64           0.3          0.001         0.9214\n",
      "43          64           0.2          0.010         0.9161\n",
      "44        1024           0.2          0.010         0.9119\n"
     ]
    }
   ],
   "source": [
    "# Convert results to a pandas DataFrame for easier viewing\n",
    "import pandas as pd\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sort results_df by test accuracy in descending order\n",
    "results_df = results_df.sort_values(by='Test Accuracy', ascending=False)\n",
    "\n",
    "# Reset the index after sorting, if desired\n",
    "results_df = results_df.reset_index(drop=True)\n",
    "\n",
    "# Display the sorted DataFrame\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
